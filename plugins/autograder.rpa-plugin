{
  "packageInfo": {
    "name": "Autograder",
    "version": "1.0.0",
    "type": "rpa-plugin"
  },
  "files": {
    "plugin.json": "{\n  \"id\": \"plugin-test\",\n  \"name\": \"Autograder\",\n  \"description\": \"Autograder\",\n  \"longDescription\": \"Autograder\",\n  \"category\": [\n    \"Data Processing\",\n    \"API Integration\",\n    \"AI\",\n    \"Automation\",\n    \"Validation\"\n  ],\n  \"version\": \"1.0.0\",\n  \"author\": \"AgentOuro\",\n  \"type\": \"pluginNode\",\n  \"nodeType\": \"pluginNode\",\n  \"color\": \"#6b7280\",\n  \"createdAt\": \"2025-10-13T03:22:40.224Z\",\n  \"updatedAt\": \"2025-11-03T23:18:47.274Z\",\n  \"timeout_mode\": \"long-running\",\n  \"max_execution_time\": 2000,\n  \"inputFields\": [\n    {\n      \"id\": \"field_1760325605785\",\n      \"type\": \"file\",\n      \"label\": \"Input 1\",\n      \"variableName\": \"submits\",\n      \"required\": true,\n      \"defaultValue\": null\n    },\n    {\n      \"id\": \"field_1760325620134\",\n      \"type\": \"file\",\n      \"label\": \"Input 2\",\n      \"variableName\": \"rubric\",\n      \"required\": true,\n      \"defaultValue\": null\n    },\n    {\n      \"id\": \"field_1760421983856\",\n      \"type\": \"llmConfig\",\n      \"label\": \"Input 3\",\n      \"variableName\": \"LLM\",\n      \"required\": true\n    },\n    {\n      \"id\": \"field_1761531538999\",\n      \"type\": \"text\",\n      \"label\": \"Input 4\",\n      \"variableName\": \"prompt\",\n      \"required\": false\n    }\n  ],\n  \"outputFields\": [\n    {\n      \"id\": \"output_1760325629470\",\n      \"type\": \"file\",\n      \"label\": \"Output 1\",\n      \"variableName\": \"report\"\n    }\n  ],\n  \"globalVariableAccess\": [],\n  \"dependencies\": [\n    \"PyPDF2\"\n  ]\n}",
    "index.py": "def run(inputs, ctx):\n    \"\"\"\n    Auto-Grader Plugin - Grades student submissions using LLM\n\n    Required inputs:\n    - rubric: PDF rubric file (base64 encoded)\n    - submits: ZIP file with student submissions (base64 encoded)\n    - LLM: LLM configuration {baseUrl, apiKey, model}\n    - maxConc: Max concurrent requests (int, default: 3)\n    - prompt: Custom grading prompt template (string, optional)\n    \"\"\"\n\n    import asyncio\n    import base64\n    import datetime\n    import io\n    import json\n    import os\n    import re\n    import zipfile\n    from pathlib import Path\n    from typing import Dict, List, Optional\n\n    # ========================================================================\n    # DATA MODELS\n    # ========================================================================\n\n    class StudentSubmission:\n        \"\"\"Represents a single student's submission\"\"\"\n        def __init__(self, name: str, files: Dict[str, bytes]):\n            self.name = name\n            self.files = files\n            self.extracted_text = \"\"\n            self.grade_result = None\n            self.error = None\n\n\n    class GradingConfig:\n        \"\"\"Configuration for grading process\"\"\"\n        def __init__(self, base_url: str, api_key: str, model: str, **kwargs):\n            self.base_url = base_url\n            self.api_key = api_key\n            self.model = model\n            self.max_concurrency = kwargs.get('max_concurrency', 3)\n            self.http_timeout_sec = kwargs.get('http_timeout_sec', 120)\n            self.student_name_regex = kwargs.get('student_name_regex')\n            self.max_chars_per_file = kwargs.get('max_chars_per_file', 50000)\n            self.max_chars_per_student = kwargs.get('max_chars_per_student', 300000)\n            self.csv_preview_rows = kwargs.get('csv_preview_rows', 100)\n            self.custom_prompt = kwargs.get('custom_prompt')\n\n\n    # ========================================================================\n    # TEXT EXTRACTION FUNCTIONS\n    # ========================================================================\n\n    def extract_text_from_pdf(content: bytes) -> str:\n        \"\"\"Extract text from PDF bytes\"\"\"\n        try:\n            import PyPDF2\n            pdf_file = io.BytesIO(content)\n            reader = PyPDF2.PdfReader(pdf_file)\n            text = []\n            for page in reader.pages:\n                text.append(page.extract_text())\n            return \"\\n\\n\".join(text)\n        except Exception as e:\n            return f\"[PDF extraction error: {e}]\"\n\n\n    def extract_text_from_ipynb(content: bytes, max_output_chars: int = 2000) -> str:\n        \"\"\"Extract text and code from Jupyter notebook with output truncation\"\"\"\n        try:\n            notebook = json.loads(content.decode('utf-8'))\n            cells = notebook.get('cells', [])\n            extracted = []\n\n            for cell in cells:\n                cell_type = cell.get('cell_type', '')\n                source = cell.get('source', [])\n\n                if isinstance(source, list):\n                    source_text = ''.join(source)\n                else:\n                    source_text = source\n\n                if cell_type == 'markdown':\n                    extracted.append(f\"## Markdown\\n{source_text}\\n\")\n                elif cell_type == 'code':\n                    extracted.append(f\"```python\\n{source_text}\\n```\\n\")\n\n                    outputs = cell.get('outputs', [])\n                    for output in outputs:\n                        if 'text' in output:\n                            text_out = output['text']\n                            if isinstance(text_out, list):\n                                text_out = ''.join(text_out)\n\n                            if len(text_out) > max_output_chars:\n                                text_out = text_out[:max_output_chars] + f\"\\n...[truncated {len(text_out) - max_output_chars} chars]\"\n\n                            extracted.append(f\"Output:\\n{text_out}\\n\")\n\n            return \"\\n\".join(extracted)\n        except Exception as e:\n            return f\"[IPYNB extraction error: {e}]\"\n\n\n    def extract_text_from_csv(content: bytes, max_rows: int = 100) -> str:\n        \"\"\"Extract CSV with header + limited rows to avoid token overload\"\"\"\n        try:\n            text = content.decode('utf-8', errors='ignore')\n            lines = text.split('\\n')\n\n            if len(lines) <= max_rows + 1:\n                return text\n\n            preview = '\\n'.join(lines[:max_rows + 1])\n            total_rows = len(lines) - 1\n            truncated_rows = total_rows - max_rows\n\n            return f\"{preview}\\n\\n[... {truncated_rows} more rows truncated for brevity. Total rows: {total_rows}]\"\n        except Exception as e:\n            return f\"[CSV extraction error: {e}]\"\n\n\n    def should_skip_file(filename: str) -> bool:\n        \"\"\"Check if file should be skipped (e.g., __MACOSX metadata)\"\"\"\n        path_parts = Path(filename).parts\n        if any(part.startswith('__MACOSX') or part.startswith('._') for part in path_parts):\n            return True\n        return False\n\n\n    def truncate_text(text: str, max_chars: int) -> str:\n        \"\"\"Truncate text to max characters with a message\"\"\"\n        if len(text) <= max_chars:\n            return text\n        return text[:max_chars] + f\"\\n\\n[... truncated {len(text) - max_chars} characters for brevity]\"\n\n\n    def extract_text_from_file(\n        filename: str,\n        content: bytes,\n        max_chars: int = 50000,\n        csv_preview_rows: int = 100\n    ) -> str:\n        \"\"\"Extract text from various file types with size limits\"\"\"\n        ext = Path(filename).suffix.lower()\n\n        try:\n            if ext == '.pdf':\n                text = extract_text_from_pdf(content)\n            elif ext == '.ipynb':\n                text = extract_text_from_ipynb(content)\n            elif ext == '.csv':\n                text = extract_text_from_csv(content, max_rows=csv_preview_rows)\n            elif ext in ['.py', '.txt', '.md']:\n                text = content.decode('utf-8', errors='ignore')\n            else:\n                return f\"[Skipped unsupported file type: {ext}]\"\n\n            return truncate_text(text, max_chars)\n\n        except Exception as e:\n            return f\"[Extraction error for {filename}: {e}]\"\n\n\n    # ========================================================================\n    # ZIP EXTRACTION FUNCTIONS\n    # ========================================================================\n\n    def extract_student_name(path: str, name_regex: Optional[str] = None) -> str:\n        \"\"\"Extract student name from path using regex or default logic\"\"\"\n        if name_regex:\n            match = re.search(name_regex, path)\n            if match:\n                return match.group(1) if match.groups() else match.group(0)\n\n        parts = Path(path).parts\n        if len(parts) > 1:\n            return parts[0]\n        return Path(path).stem\n\n\n    def extract_submissions_from_zip(\n        zip_content: bytes,\n        name_regex: Optional[str] = None,\n        ctx=None\n    ) -> List[StudentSubmission]:\n        \"\"\"Extract student submissions from ZIP file. Handles nested ZIPs.\"\"\"\n        students: Dict[str, StudentSubmission] = {}\n\n        def process_zip(zip_bytes: bytes, parent_path: str = \"\"):\n            \"\"\"Recursively process ZIP files\"\"\"\n            with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:\n                for info in zf.filelist:\n                    if info.is_dir():\n                        continue\n\n                    if should_skip_file(info.filename):\n                        continue\n\n                    full_path = os.path.join(parent_path, info.filename)\n                    file_content = zf.read(info.filename)\n\n                    if info.filename.lower().endswith('.zip'):\n                        zip_stem = Path(info.filename).stem\n                        process_zip(file_content, zip_stem)\n                        continue\n\n                    student_name = extract_student_name(full_path, name_regex)\n\n                    if student_name not in students:\n                        students[student_name] = StudentSubmission(\n                            name=student_name,\n                            files={}\n                        )\n\n                    students[student_name].files[info.filename] = file_content\n\n        try:\n            process_zip(zip_content)\n            if ctx:\n                ctx.log(f\"Extracted submissions for {len(students)} students\")\n            return list(students.values())\n        except Exception as e:\n            if ctx:\n                ctx.log(f\"Failed to extract submissions: {e}\")\n            raise\n\n\n    def combine_student_files(submission: StudentSubmission, config: GradingConfig, ctx=None) -> str:\n        \"\"\"Combine all extracted text from student's files with size limits\"\"\"\n        texts = []\n        total_chars = 0\n\n        for filename, content in submission.files.items():\n            ext = Path(filename).suffix.lower()\n            if ext in ['.pdf', '.ipynb', '.py', '.txt', '.md', '.csv']:\n                text = extract_text_from_file(\n                    filename,\n                    content,\n                    max_chars=config.max_chars_per_file,\n                    csv_preview_rows=config.csv_preview_rows\n                )\n                file_section = f\"\\n{'='*60}\\nFile: {filename}\\n{'='*60}\\n{text}\"\n\n                if total_chars + len(file_section) > config.max_chars_per_student:\n                    remaining = config.max_chars_per_student - total_chars\n                    if remaining > 100:\n                        file_section = file_section[:remaining] + \"\\n\\n[... truncated due to student size limit]\"\n                        texts.append(file_section)\n                    break\n\n                texts.append(file_section)\n                total_chars += len(file_section)\n\n        combined = \"\\n\\n\".join(texts)\n\n        if len(combined) > config.max_chars_per_student:\n            combined = combined[:config.max_chars_per_student] + \"\\n\\n[... truncated to stay within size limits]\"\n            if ctx:\n                ctx.log(f\"WARNING: Student {submission.name} submission truncated to {config.max_chars_per_student} chars\")\n\n        return combined\n\n\n    # ========================================================================\n    # LLM GRADING FUNCTIONS\n    # ========================================================================\n\n    async def grade_student_with_llm(\n        student: StudentSubmission,\n        rubric_text: str,\n        config: GradingConfig,\n        semaphore: asyncio.Semaphore,\n        ctx\n    ) -> StudentSubmission:\n        \"\"\"Grade a single student's submission using LLM via ctx.http_fetch\"\"\"\n        async with semaphore:\n            ctx.heartbeat()\n\n            try:\n                ctx.log(f\"Grading: {student.name}\")\n\n                # Use custom prompt if provided, otherwise use default\n                if config.custom_prompt:\n                    prompt = config.custom_prompt.replace(\"{rubric}\", rubric_text).replace(\"{submission}\", student.extracted_text)\n                else:\n                    prompt = f\"\"\"You are an expert grader. Grade this student's submission according to the rubric below.\n\nRUBRIC:\n{rubric_text}\n\nSTUDENT SUBMISSION:\n{student.extracted_text}\n\nPlease provide:\n1. A detailed assessment of the submission against each rubric criterion\n2. Specific strengths and areas for improvement\n3. A final grade/score (if applicable based on the rubric)\n\nFormat your response in clear Markdown.\"\"\"\n\n                # Prepare HTTP request for ctx.http_fetch\n                request_data = {\n                    \"url\": config.base_url,\n                    \"method\": \"POST\",\n                    \"headers\": {\n                        \"Authorization\": f\"Bearer {config.api_key}\",\n                        \"Content-Type\": \"application/json\"\n                    },\n                    \"body\": json.dumps({\n                        \"model\": config.model,\n                        \"messages\": [\n                            {\n                                \"role\": \"user\",\n                                \"content\": prompt\n                            }\n                        ]\n                    }),\n                    \"timeoutMs\": config.http_timeout_sec * 1000\n                }\n\n                # ctx.http_fetch is SYNC, run in executor\n                loop = asyncio.get_event_loop()\n                response = await loop.run_in_executor(\n                    None,\n                    ctx.http_fetch,\n                    request_data\n                )\n\n                ctx.heartbeat()\n\n                # Check response status\n                if response.get(\"status\") != 200:\n                    error_msg = f\"API error {response.get('status')}: {response.get('data', 'Unknown error')}\"\n                    ctx.log(f\"Failed to grade {student.name}: {error_msg}\")\n                    student.error = error_msg\n                    return student\n\n                # Parse response\n                result = response.get(\"data\")\n                student.grade_result = result['choices'][0]['message']['content']\n                ctx.log(f\"✓ Completed: {student.name}\")\n\n                ctx.heartbeat()\n\n            except Exception as e:\n                error_msg = f\"Unexpected error: {str(e)}\"\n                ctx.log(f\"Failed to grade {student.name}: {error_msg}\")\n                student.error = error_msg\n                ctx.heartbeat()\n\n            return student\n\n\n    async def grade_all_students(\n        students: List[StudentSubmission],\n        rubric_text: str,\n        config: GradingConfig,\n        ctx\n    ) -> List[StudentSubmission]:\n        \"\"\"Grade all students with bounded concurrency\"\"\"\n        semaphore = asyncio.Semaphore(config.max_concurrency)\n\n        ctx.log(f\"Starting grading for {len(students)} students (concurrency: {config.max_concurrency})\")\n        ctx.heartbeat()\n\n        tasks = [\n            grade_student_with_llm(student, rubric_text, config, semaphore, ctx)\n            for student in students\n        ]\n\n        results = await asyncio.gather(*tasks)\n\n        graded = sum(1 for s in results if s.grade_result is not None)\n        failed = sum(1 for s in results if s.error is not None)\n\n        ctx.log(f\"Grading complete: {graded} succeeded, {failed} failed\")\n        ctx.heartbeat()\n\n        return results\n\n\n    # ========================================================================\n    # REPORT GENERATION FUNCTIONS\n    # ========================================================================\n\n    def generate_student_report(student: StudentSubmission) -> str:\n        \"\"\"Generate Markdown report for a single student\"\"\"\n        lines = [\n            f\"# Grading Report: {student.name}\",\n            f\"\\n**Generated:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n            \"\\n---\\n\"\n        ]\n\n        if student.error:\n            lines.append(f\"## ⚠️ Error\\n\\n{student.error}\\n\")\n            lines.append(\"\\n## Submission Files\\n\")\n            for filename in student.files.keys():\n                lines.append(f\"- {filename}\")\n        else:\n            lines.append(\"## Grade Assessment\\n\")\n            lines.append(student.grade_result or \"[No result]\")\n\n            lines.append(\"\\n\\n## Submission Files\\n\")\n            for filename in student.files.keys():\n                lines.append(f\"- {filename}\")\n\n        return \"\\n\".join(lines)\n\n\n    def generate_summary_report(students: List[StudentSubmission]) -> str:\n        \"\"\"Generate summary report for all students\"\"\"\n        graded = [s for s in students if s.grade_result is not None]\n        failed = [s for s in students if s.error is not None]\n\n        lines = [\n            \"# Auto-Grader Summary Report\",\n            f\"\\n**Generated:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n            f\"\\n**Total Students:** {len(students)}\",\n            f\"**Successfully Graded:** {len(graded)}\",\n            f\"**Failed:** {len(failed)}\",\n            \"\\n---\\n\"\n        ]\n\n        if failed:\n            lines.append(\"\\n## ⚠️ Failed Gradings\\n\")\n            for student in failed:\n                lines.append(f\"- **{student.name}**: {student.error}\")\n\n        lines.append(\"\\n## Students Processed\\n\")\n        for student in students:\n            status = \"✓\" if student.grade_result else \"✗\"\n            lines.append(f\"{status} {student.name}\")\n\n        return \"\\n\".join(lines)\n\n\n    def create_results_zip(students: List[StudentSubmission]) -> bytes:\n        \"\"\"Create ZIP file containing all student reports and summary\"\"\"\n        zip_buffer = io.BytesIO()\n\n        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:\n            for student in students:\n                report = generate_student_report(student)\n                safe_name = re.sub(r'[^\\w\\s-]', '_', student.name)\n                zf.writestr(f\"{safe_name}.md\", report)\n\n            summary = generate_summary_report(students)\n            zf.writestr(\"SUMMARY.md\", summary)\n\n        return zip_buffer.getvalue()\n\n\n    # ========================================================================\n    # MAIN EXECUTION\n    # ========================================================================\n\n    try:\n        ctx.log(\"=\" * 70)\n        ctx.log(\"AUTO-GRADER PLUGIN STARTED\")\n        ctx.log(\"=\" * 70)\n        ctx.heartbeat()\n\n        # Extract and validate inputs\n        rubric_input = inputs.get(\"rubric\")\n        submits_input = inputs.get(\"submits\")\n\n        if not rubric_input or not submits_input:\n            raise ValueError(\"Missing required inputs: rubric and submits\")\n\n        # Extract LLM configuration\n        llm_cfg = inputs.get(\"LLM\", {})\n        base_url = llm_cfg.get(\"baseUrl\", \"https://openrouter.ai/api/v1\")\n        if not base_url.endswith(\"/chat/completions\"):\n            base_url = base_url.rstrip(\"/\") + \"/chat/completions\"\n\n        api_key = llm_cfg.get(\"apiKey\")\n        model = llm_cfg.get(\"model\", \"openai/gpt-4o-mini\")\n\n        if not api_key:\n            raise ValueError(\"Missing required input: LLM.apiKey\")\n\n        # Decode base64 files\n        ctx.log(\"Decoding uploaded files...\")\n        rubric_content = base64.b64decode(rubric_input.get(\"content\", \"\"))\n        submits_content = base64.b64decode(submits_input.get(\"content\", \"\"))\n        ctx.heartbeat()\n\n        # Extract rubric text\n        ctx.log(\"Extracting rubric text...\")\n        rubric_text = extract_text_from_pdf(rubric_content)\n        ctx.log(f\"Rubric extracted ({len(rubric_text)} characters)\")\n        ctx.heartbeat()\n\n        # Extract student submissions\n        ctx.log(\"Extracting student submissions...\")\n        students = extract_submissions_from_zip(\n            submits_content,\n            name_regex=None,\n            ctx=ctx\n        )\n\n        if not students:\n            raise ValueError(\"No student submissions found in ZIP\")\n\n        ctx.heartbeat()\n\n        # Configure grading\n        config = GradingConfig(\n            base_url=base_url,\n            api_key=api_key,\n            model=model,\n            max_concurrency=inputs.get(\"maxConc\", 3),\n            http_timeout_sec=120,\n            student_name_regex=None,\n            max_chars_per_file=50000,\n            max_chars_per_student=300000,\n            csv_preview_rows=100,\n            custom_prompt=inputs.get(\"prompt\")\n        )\n\n        # Extract text from student files\n        ctx.log(\"Extracting text from student files...\")\n        for student in students:\n            student.extracted_text = combine_student_files(student, config, ctx)\n        ctx.heartbeat()\n\n        # Grade all students using asyncio\n        ctx.log(f\"Starting LLM grading (model: {config.model})...\")\n\n        # Use safe_async() helper from main.py template\n        graded_students = safe_async(\n            grade_all_students(students, rubric_text, config, ctx)\n        )\n        ctx.heartbeat()\n\n        # Generate reports and ZIP\n        ctx.log(\"Generating reports...\")\n        results_zip = create_results_zip(graded_students)\n        ctx.heartbeat()\n\n        # Save artifact\n        artifact_handle = ctx.save_bytes(\n            data=results_zip,\n            suffix=\".zip\"\n        )\n\n        # Read back and encode\n        artifact_bytes = ctx.read_bytes(artifact_handle)\n        artifact_base64 = base64.b64encode(artifact_bytes).decode('utf-8')\n\n        # Statistics\n        graded_count = sum(1 for s in graded_students if s.grade_result is not None)\n        failed_count = sum(1 for s in graded_students if s.error is not None)\n\n        ctx.log(\"=\" * 70)\n        ctx.log(f\"GRADING COMPLETE: {graded_count}/{len(students)} succeeded, {failed_count} failed\")\n        ctx.log(\"=\" * 70)\n        ctx.heartbeat()\n\n        # Return result\n        return {\n            \"name\": \"grading_results.zip\",\n            \"content\": artifact_base64,\n            \"extension\": \".zip\",\n            \"type\": \"application/zip\",\n            \"size\": len(artifact_bytes)\n        }\n\n    except Exception as e:\n        ctx.log(f\"ERROR: {str(e)}\")\n        ctx.heartbeat()\n        raise\n\n"
  }
}